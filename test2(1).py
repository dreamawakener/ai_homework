import openai
import sys
import time
import requests
import xml.etree.ElementTree as ET
from urllib.parse import quote
import re
from datetime import datetime, timedelta
from typing import List, Dict
from camel.agents import ChatAgent
from camel.models import ModelFactory
from camel.types import ModelPlatformType
from camel.utils import print_text_animated
from colorama import Fore, init
from camel.societies import RolePlaying
from dotenv import load_dotenv
import os
import json
from bs4 import BeautifulSoup
from datetime import datetime
from urllib.parse import quote
# åˆå§‹åŒ–colorama
init(autoreset=True)


# å¯¼å…¥é…ç½®ç®¡ç†
from config import get_api_key, get_base_url, get_model_name

my_api_key = get_api_key()
my_base_url = get_base_url()
my_model_name = get_model_name()


class ArxivCrawler:
    """ArXivè®ºæ–‡çˆ¬è™« - ä½¿ç”¨ç½‘é¡µæœç´¢"""

    def __init__(self):
        self.base_url = "https://arxiv.org/search/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.openai_client = openai.OpenAI(api_key=my_api_key, base_url=my_base_url)
        self.model_name = my_model_name
    def translate_query(self, query: str) -> str:
        """å°†ä¸­æ–‡æŸ¥è¯¢è¯ç¿»è¯‘ä¸ºè‹±æ–‡"""
        try:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
            if any('\u4e00' <= char <= '\u9fff' for char in query):
                print(Fore.YELLOW + f"ğŸ” æ£€æµ‹åˆ°ä¸­æ–‡æŸ¥è¯¢è¯: {query}ï¼Œæ­£åœ¨ç¿»è¯‘...")
                # æ„å»ºç¿»è¯‘æç¤º
                prompt = f"è¯·å°†ä»¥ä¸‹ä¸­æ–‡æŸ¥è¯¢è¯ç¿»è¯‘ä¸ºè‹±æ–‡ï¼Œç”¨äºå­¦æœ¯æ–‡çŒ®æœç´¢ï¼š\n{query}"
                response = self.openai_client.chat.completions.create(
                    model=self.model_name,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å­¦æœ¯ç¿»è¯‘ä¸“å®¶ï¼Œéœ€å°†ä¸­æ–‡å‡†ç¡®è¯‘ä¸ºè‹±æ–‡å­¦æœ¯å…³é”®è¯"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.2,
                    max_tokens=100
                )
                # æå–ç¿»è¯‘ç»“æœï¼ˆå»é™¤å¯èƒ½çš„æ ‡ç‚¹å’Œå¤šä½™ç©ºæ ¼ï¼‰
                translation = response.choices[0].message.content.strip()
                # å¤„ç†å¯èƒ½çš„æ ‡ç‚¹ç¬¦å·ï¼ˆå¦‚ç»“å°¾çš„å¥å·ï¼‰
                if translation.endswith('.'):
                    translation = translation[:-1]
                print(Fore.GREEN + f"âœ… ç¿»è¯‘å®Œæˆ: {translation}")
                return translation
            return query  # éä¸­æ–‡ç›´æ¥è¿”å›åŸè¯
        except Exception as e:
            print(Fore.RED + f"âŒ ç¿»è¯‘å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸè¯æœç´¢")
            return query
    def search_papers(self, query: str, max_results: int = 50) -> List[Dict]:
        """
        ä»ArXivæœç´¢ç›¸å…³è®ºæ–‡
        Args:
            query: æœç´¢å…³é”®è¯
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°
        Returns:
            è®ºæ–‡ä¿¡æ¯åˆ—è¡¨
        """
        translated_query = self.translate_query(query)
        print(Fore.YELLOW + f"ğŸ” æ­£åœ¨ArXivæœç´¢: {translated_query}")

        papers = []
        page = 0
        per_page = 50  # ArXivæ¯é¡µæœ€å¤šæ˜¾ç¤º50ç¯‡è®ºæ–‡

        try:
            while len(papers) < max_results:
                # æ„å»ºæœç´¢URL
                params = {
                    'query': translated_query,
                    'searchtype': 'all',
                    'source': 'header',
                    'start': page * per_page
                }

                print(Fore.CYAN + f"ğŸŒ æ­£åœ¨è·å–ç¬¬ {page + 1} é¡µ...")

                response = requests.get(self.base_url, params=params, headers=self.headers, timeout=30)
                response.raise_for_status()

                soup = BeautifulSoup(response.content, 'html.parser')

                # æŸ¥æ‰¾è®ºæ–‡æ¡ç›®
                paper_items = soup.find_all('li', class_='arxiv-result')

                if not paper_items:
                    print(Fore.YELLOW + f"âš ï¸  ç¬¬ {page + 1} é¡µæ²¡æœ‰æ‰¾åˆ°è®ºæ–‡ï¼Œåœæ­¢æœç´¢")
                    break

                print(Fore.GREEN + f"âœ… ç¬¬ {page + 1} é¡µæ‰¾åˆ° {len(paper_items)} ç¯‡è®ºæ–‡")

                # è§£ææ¯ç¯‡è®ºæ–‡
                for item in paper_items:
                    if len(papers) >= max_results:
                        break

                    paper_info = self._parse_paper_item(item)
                    if paper_info:
                        papers.append(paper_info)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
                if len(paper_items) < per_page:
                    break

                page += 1
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«

        except requests.RequestException as e:
            print(Fore.RED + f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
        except Exception as e:
            print(Fore.RED + f"âŒ è§£æå¤±è´¥: {e}")

        print(Fore.GREEN + f"âœ… æ€»å…±æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡")
        return papers

    def _parse_paper_item(self, item) -> Dict:
        """è§£æå•ä¸ªè®ºæ–‡æ¡ç›®"""
        try:
            # è·å–æ ‡é¢˜
            title = item.find('p', class_="title is-5 mathjax").text
            if title:
                # print(title)
                pass
            else:
                title = "æœªçŸ¥æ ‡é¢˜"
                print("è·å–æ ‡é¢˜å¤±è´¥")

            # è·å–æ‘˜è¦é“¾æ¥
            abs_link = item.find('p', class_='list-title is-inline-block').find('a')['href']
            if abs_link:
                # print(abs_link)
                pass
            else:
                abs_link = "#"
                print("è·å–abs_linkå¤±è´¥")

            # è·å–ArXiv ID
            arxiv_id = item.find('p', class_='list-title is-inline-block').find('a').text.split(':')[1]
            if arxiv_id:
                # print(arxiv_id)
                pass
            else:
                arxiv_id = "æœªçŸ¥ID"
                print("è·å–arxiv_idå¤±è´¥")

            # æ„å»ºPDFé“¾æ¥
            pdf_link = f"https://arxiv.org/pdf/{arxiv_id}" if arxiv_id else "#"

            # è·å–ä½œè€…
            authors = []
            authors_elem = item.find('p', class_='authors')
            if authors_elem:
                author_links = authors_elem.find_all('a')
                for author_link in author_links:
                    authors.append(author_link.text.strip())

            # è·å–æ‘˜è¦
            abstract_elem = item.find('p', class_='abstract')
            if abstract_elem:
                abstract_text = abstract_elem.text.strip()
                if abstract_text.startswith('Abstract:'):
                    summary = abstract_text[9:].strip()
            else:
                summary = "æ— æ‘˜è¦"

            # è·å–å‘å¸ƒæ—¥æœŸ
            submitted_elem = item.find('p', class_='is-size-7')
            published_date = submitted_elem.text.strip() if submitted_elem else "æœªçŸ¥æ—¥æœŸ"

            # è·å–åˆ†ç±»ä¿¡æ¯
            categories = []
            subject_elem = item.find('div', class_='tags is-inline-block')
            if subject_elem:
                tag_links = subject_elem.find_all(class_='tag')
                for tag_link in tag_links:
                    category = tag_link.text.strip()
                    if category:
                        categories.append(category)

            # é™åˆ¶æ‘˜è¦é•¿åº¦
            if len(summary) > 500:
                summary = summary[:500] + '...'

            return {
                'title': title,
                'authors': authors,
                'summary': summary,
                'published_date': published_date,
                'arxiv_id': arxiv_id,
                'pdf_link': pdf_link,
                'abs_link': abs_link,
                'categories': categories,
                'authors_str': ', '.join(authors[:3]) + (' et al.' if len(authors) > 3 else '')
            }

        except Exception as e:
            print(Fore.RED + f"âŒ è§£æè®ºæ–‡æ¡ç›®å¤±è´¥: {e}")
            return None

class PaperValueAssessmentAgent:
    """è®ºæ–‡ä»·å€¼è¯„ä¼°ä»£ç†"""

    def __init__(self):
        self.client = openai.OpenAI(api_key=my_api_key, base_url=my_base_url)
        self.model = my_model_name

    def assess_papers(self, papers: List[Dict], theme: str, subject: str, outline: str) -> List[Dict]:
        """
        è¯„ä¼°è®ºæ–‡ä»·å€¼å¹¶æ’åº

        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            theme: è®ºæ–‡ä¸»é¢˜æ–¹å‘
            subject: å…·ä½“ä¸»é¢˜
            outline: è®ºæ–‡æçº²

        Returns:
            æŒ‰ä»·å€¼æ’åºçš„è®ºæ–‡åˆ—è¡¨
        """
        print(Fore.YELLOW + f"ğŸ¯ æ­£åœ¨è¯„ä¼° {len(papers)} ç¯‡è®ºæ–‡çš„å‚è€ƒä»·å€¼...")

        # æ„å»ºè¯„ä¼°æç¤º
        assessment_prompt = self._build_assessment_prompt(papers, theme, subject, outline)

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system",
                    "content": "ä½ æ˜¯ä¸€åå­¦æœ¯è¯„ä¼°ä¸“å®¶ï¼Œéœ€è¦æ ¹æ®è®ºæ–‡ä¸ç»™å®šä¸»é¢˜çš„ç›¸å…³æ€§ã€å¼•ç”¨ä»·å€¼ã€ç ”ç©¶è´¨é‡ç­‰å› ç´ å¯¹è®ºæ–‡è¿›è¡Œè¯„åˆ†æ’åºã€‚"},
                    {"role": "user", "content": assessment_prompt}
                ],
                temperature=0.3,
                max_tokens=4096
            )

            assessment_result = response.choices[0].message.content
            ranked_papers = self._parse_assessment_result(assessment_result, papers)

            print(Fore.GREEN + f"âœ… è®ºæ–‡ä»·å€¼è¯„ä¼°å®Œæˆï¼Œæ¨èå‰ {min(10, len(ranked_papers))} ç¯‡")
            return ranked_papers[:10]  # è¿”å›å‰10ç¯‡

        except Exception as e:
            print(Fore.RED + f"âŒ è®ºæ–‡è¯„ä¼°å¤±è´¥: {e}")
            # å¦‚æœè¯„ä¼°å¤±è´¥ï¼ŒæŒ‰å‘å¸ƒæ—¶é—´æ’åºè¿”å›
            return sorted(papers, key=lambda x: x['published_date'], reverse=True)[:10]

    def _build_assessment_prompt(self, papers: List[Dict], theme: str, subject: str, outline: str) -> str:
        """æ„å»ºè¯„ä¼°æç¤º"""
        papers_info = ""
        for i, paper in enumerate(papers, 1):
            papers_info += f"""
è®ºæ–‡{i}:
- æ ‡é¢˜: {paper['title']}
- ä½œè€…: {paper['authors_str']}
- æ‘˜è¦: {paper['summary']}
- å‘å¸ƒæ—¶é—´: {paper['published_date']}
- åˆ†ç±»: {', '.join(paper['categories'][:3])}
---
"""

        prompt = f"""
è¯·è¯„ä¼°ä»¥ä¸‹è®ºæ–‡å¯¹äº"{theme}"é¢†åŸŸä¸­"{subject}"ä¸»é¢˜ç ”ç©¶çš„å‚è€ƒä»·å€¼ã€‚

ç ”ç©¶æçº²:
{outline}

å¾…è¯„ä¼°è®ºæ–‡:
{papers_info}

è¯„ä¼°æ ‡å‡†:
1. ä¸ç ”ç©¶ä¸»é¢˜çš„ç›¸å…³æ€§ (40%)
2. ç ”ç©¶æ–¹æ³•çš„åˆ›æ–°æ€§å’Œä¸¥è°¨æ€§ (25%)
3. å‘è¡¨æ—¶é—´çš„æ–°é¢–æ€§ (20%)
4. ä½œè€…æƒå¨æ€§å’ŒæœŸåˆŠè´¨é‡ (15%)

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼ŒåŒ…å«æ¯ç¯‡è®ºæ–‡çš„è¯„åˆ†(1-10åˆ†)å’Œæ’åº:
```json
{{
  "rankings": [
    {{
      "paper_index": 1,
      "score": 8.5,
      "reasoning": "ç›¸å…³æ€§é«˜ï¼Œæ–¹æ³•åˆ›æ–°..."
    }},
    ...
  ]
}}
```

è¯·ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼ŒæŒ‰è¯„åˆ†ä»é«˜åˆ°ä½æ’åºã€‚
"""
        return prompt

    def _parse_assessment_result(self, assessment_result: str, papers: List[Dict]) -> List[Dict]:
        """è§£æè¯„ä¼°ç»“æœ"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', assessment_result, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                assessment_data = json.loads(json_str)

                # æŒ‰è¯„ä¼°ç»“æœæ’åºè®ºæ–‡
                ranked_papers = []
                for ranking in assessment_data.get('rankings', []):
                    paper_index = ranking.get('paper_index', 1) - 1  # è½¬æ¢ä¸º0åŸºç´¢å¼•
                    if 0 <= paper_index < len(papers):
                        paper = papers[paper_index].copy()
                        paper['assessment_score'] = ranking.get('score', 0)
                        paper['assessment_reasoning'] = ranking.get('reasoning', '')
                        ranked_papers.append(paper)

                return ranked_papers

        except (json.JSONDecodeError, KeyError) as e:
            print(Fore.YELLOW + f"âš ï¸  è¯„ä¼°ç»“æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ’åº: {e}")

        # å¦‚æœè§£æå¤±è´¥ï¼ŒæŒ‰å‘å¸ƒæ—¶é—´æ’åº
        return sorted(papers, key=lambda x: x['published_date'], reverse=True)

class StreamingChatAgent:
    """å¸¦æµå¼å“åº”åŠŸèƒ½çš„èŠå¤©ä»£ç†"""

    def __init__(self, system_message="", output_language="zh"):
        self.client = openai.OpenAI(api_key=my_api_key, base_url=my_base_url)
        self.model = my_model_name
        self.system_message = system_message
        self.output_language = output_language
        self.conversation_history = []

        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯åˆ°å¯¹è¯å†å²
        if system_message:
            self.conversation_history.append({"role": "system", "content": system_message})

    def stream_step(self, message: str, typing_delay: float = 0.001, show_role_prefix: str = ""):
        """æµå¼å“åº”å¤„ç†"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.conversation_history.append({"role": "user", "content": message})

        try:
            # åˆ›å»ºæµå¼è¯·æ±‚
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=self.conversation_history,
                temperature=0.8,
                max_tokens=8192,
                stream=True  # å¯ç”¨æµå¼è¾“å‡º
            )

            full_response = ""
            if show_role_prefix:
                print(show_role_prefix, end="", flush=True)

            # é€å—å¤„ç†æµå¼å“åº”
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    full_response += content

                    # æ‰“å­—æœºæ•ˆæœè¾“å‡º
                    for char in content:
                        sys.stdout.write(char)
                        sys.stdout.flush()
                        time.sleep(typing_delay)

            print()

            # ä¿å­˜å®Œæ•´å“åº”åˆ°å¯¹è¯å†å²
            self.conversation_history.append({"role": "assistant", "content": full_response})
            return full_response

        except Exception as e:
            print(f"âŒ æµå¼è¯·æ±‚å¤±è´¥: {e}")
            return f"è¯·æ±‚å¤±è´¥: {e}"


class StreamingPaperWritingSystem:
    """å¸¦æµå¼å“åº”çš„è®ºæ–‡å†™ä½œç³»ç»Ÿ"""

    def __init__(self):
        self.camel_model = ModelFactory.create(
            model_platform = ModelPlatformType.OPENAI,
            model_type=my_model_name,
            url=my_base_url,
            api_key=my_api_key,
            model_config_dict={
                "max_tokens": 4096
            }
        )

        # åˆå§‹åŒ–å˜é‡
        self.theme = ""
        self.subject = ""
        self.outline = ""
        self.arxiv_crawler = ArxivCrawler()
        self.value_assessor = PaperValueAssessmentAgent()

    def generate_outline(self):
        self.theme = input("è¯·è¾“å…¥è®ºæ–‡ä¸»è¦æ–¹å‘ï¼ˆå¦‚ï¼šåŒ»å­¦ã€æ•°å­¦ã€è¯­æ–‡ç­‰ï¼‰ï¼š")
        self.subject = input("è¯·è¾“å…¥è®ºæ–‡ä¸»é¢˜ï¼ˆå¦‚ï¼šå¿ƒè¡€ç®¡ç–¾ç—…ã€å¾®ç§¯åˆ†ã€å¤ä»£è¯—è¯ç­‰ï¼‰ï¼š")

        # åˆ›å»ºæçº²ç”ŸæˆAgent
        outline_agent = StreamingChatAgent(
            system_message="ä½ æ˜¯ä¸€åå­¦æœ¯å†™ä½œä¸“å®¶ï¼Œéœ€ç”ŸæˆåŒ…å«ä»¥ä¸‹è¦ç´ çš„è®ºæ–‡æçº²ï¼š\n"
                           "1. ä¸¥æ ¼éµå¾ªIMRaDç»“æ„ï¼ˆå¼•è¨€ã€æ–¹æ³•ã€ç»“æœã€è®¨è®ºï¼‰\n"
                           "2. æ¯ä¸ªç« èŠ‚è‡³å°‘åŒ…å«2ä¸ªå­ç« èŠ‚\n"
                           "3. ç”¨Markdownæ ¼å¼è¾“å‡ºå±‚çº§æ ‡é¢˜",
            output_language="zh"
        )
        print(Fore.YELLOW + "\nğŸ”„ æ­£åœ¨ç”Ÿæˆæçº²...")

        self.outline = outline_agent.stream_step(
            f"è¯·ç”Ÿæˆå…³äº{self.theme}çš„æœ‰å…³{self.subject}å†…å®¹çš„è®ºæ–‡æçº²",
            typing_delay=0.01,
            show_role_prefix=""
        )

    def start_collaborative_writing(self, rounds=3):
        """å¼€å§‹åä½œå†™ä½œè¿‡ç¨‹"""
        print(Fore.MAGENTA + f"\nğŸ¯ å¼€å§‹å¸ˆç”Ÿåä½œä¼˜åŒ–ï¼ˆå…±{rounds}è½®ï¼‰")
        print("=" * 60)

        # åˆ›å»ºæµå¼ä»£ç†
        assistant_agent = StreamingChatAgent(
            system_message=f"""ä½ æ˜¯ä¸€åè¦æ±‚ä¸¥æ ¼çš„å¯¼å¸ˆ(RoleType:ASSISTANT)ï¼Œå¿…é¡»æŒ‰ä»¥ä¸‹è§„åˆ™æŒ‡å¯¼ï¼š
                            1. ç”¨'é€»è¾‘é—®é¢˜Xï¼š...'æ ¼å¼æŒ‡å‡ºæçº²ç¼ºé™·
                            2. æ¯æ¬¡åªæ1ä¸ªæ ¸å¿ƒé—®é¢˜
                            3. é¿å…ç›´æ¥ç»™å‡ºç­”æ¡ˆ
                            4. é‡ç‚¹å…³æ³¨{self.theme}é¢†åŸŸçš„{self.subject}ä¸“ä¸šé—®é¢˜""",
            output_language="zh"
        )

        user_agent = StreamingChatAgent(
            system_message=f"""ä½ æ˜¯å­¦ç”Ÿï¼ˆRoleType.USERï¼‰ï¼Œä½ æ­£åœ¨æ’°å†™å…³äº{self.theme}çš„æœ‰å…³{self.subject}å†…å®¹çš„è®ºæ–‡ï¼Œä½ çš„ä»»åŠ¡æ˜¯ï¼š
                            1. æ ¹æ®å¯¼å¸ˆçš„æ„è§å¯¹æçº²ä½œå‡ºä¿®æ”¹
                            2. æœ€ç»ˆç”Ÿæˆä¿®è®¢ç‰ˆæçº²""",
            output_language="zh"
        )

        # å­¦ç”Ÿå‘é€åˆå§‹æ¶ˆæ¯
        user_msg = f"ä»¥ä¸‹æ˜¯æˆ‘çš„è®ºæ–‡æçº²ï¼Œè¯·æ‰¹è¯„æŒ‡æ­£ï¼š\n\n{self.outline}"

        for i in range(rounds):
            # å¯¼å¸ˆæµå¼å›å¤
            print(Fore.BLUE + f"\nğŸ‘¨â€ğŸ« å¯¼å¸ˆ ç¬¬{i + 1}è½®:")
            assistant_msg = assistant_agent.stream_step(
                user_msg,
                typing_delay=0.001,
                show_role_prefix=""
            )

            # æœ€åä¸€è½®æŒ‡å¯¼åç›´æ¥ç”Ÿæˆæœ€ç»ˆæçº²
            if i + 1 == rounds:
                assistant_msg = assistant_msg + "æ³¨æ„ï¼è¿™ä¸€ç‰ˆä¿®æ”¹å®Œæ¯•åè¯·*ç›´æ¥*è¾“å‡ºå®Œæ•´çš„å¯ä»¥ç›´æ¥æ‹·è´çš„mdæ ¼å¼æçº²ï¼å¦åˆ™ä¸äºˆé€šè¿‡ï¼"

            # å­¦ç”Ÿæµå¼å›å¤
            print(Fore.GREEN + f"\nğŸ§‘â€ğŸ“ å­¦ç”Ÿ ç¬¬{i + 1}è½®å›åº”:")
            user_msg = user_agent.stream_step(
                assistant_msg,
                typing_delay=0.001,
                show_role_prefix=""
            )

        print(Fore.CYAN + "\nğŸ‰ åä½œä¼˜åŒ–å®Œæˆï¼")
        return user_msg

    def save_final_outline(self, final_outline):
        """ä¿å­˜æœ€ç»ˆæçº²"""
        filename = f"{self.theme}_{self.subject}_è®ºæ–‡æçº².md"
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# {self.theme} - {self.subject} è®ºæ–‡æçº²\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write("## æœ€ç»ˆä¼˜åŒ–æçº²\n\n")
                f.write(final_outline)

            print(Fore.GREEN + f"\nğŸ’¾ æœ€ç»ˆæçº²å·²ä¿å­˜è‡³: {filename}")
        except Exception as e:
            print(Fore.RED + f"\nâŒ ä¿å­˜å¤±è´¥: {e}")

    def search_and_save_references(self, final_outline):
        """ä½¿ç”¨ArXivçˆ¬è™«æœç´¢å¹¶è¯„ä¼°å‚è€ƒæ–‡çŒ®"""
        print(Fore.YELLOW + "\nğŸ” æ­£åœ¨ä»ArXivæœç´¢ç›¸å…³è®ºæ–‡...")

        # æ„å»ºæœç´¢å…³é”®è¯
        search_query = f"{self.subject} {self.theme}"

        # çˆ¬å–è®ºæ–‡
        papers = self.arxiv_crawler.search_papers(search_query, max_results=50)

        if not papers:
            print(Fore.RED + "âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
            return

        # è¯„ä¼°è®ºæ–‡ä»·å€¼
        ranked_papers = self.value_assessor.assess_papers(papers, self.theme, self.subject, final_outline)

        # ä¿å­˜å‚è€ƒæ–‡çŒ®
        filename = f"{self.theme}_{self.subject}_å‚è€ƒæ–‡çŒ®.md"
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(f"# {self.theme} - {self.subject} å‚è€ƒæ–‡çŒ®\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**æœç´¢å…³é”®è¯**: {search_query}\n")
                f.write(f"**æ€»å…±æ‰¾åˆ°**: {len(papers)} ç¯‡è®ºæ–‡\n")
                f.write(f"**æ¨è**: å‰ {len(ranked_papers)} ç¯‡é«˜ä»·å€¼è®ºæ–‡\n\n")

                f.write("## æ¨èæ–‡çŒ®åˆ—è¡¨\n\n")

                for i, paper in enumerate(ranked_papers, 1):
                    f.write(f"### {i}. {paper['title']}\n\n")
                    f.write(f"**ä½œè€…**: {paper['authors_str']}\n\n")
                    f.write(f"**å‘å¸ƒæ—¶é—´**: {paper['published_date']}\n\n")
                    f.write(f"**ArXiv ID**: {paper['arxiv_id']}\n\n")
                    f.write(f"**åˆ†ç±»**: {', '.join(paper['categories'][:3])}\n\n")
                    f.write(f"**é“¾æ¥**: \n")
                    f.write(f"- [è®ºæ–‡æ‘˜è¦]({paper['abs_link']})\n")
                    f.write(f"- [PDFä¸‹è½½]({paper['pdf_link']})\n\n")
                    f.write(f"**æ‘˜è¦**: {paper['summary']}\n\n")

                    if 'assessment_score' in paper:
                        f.write(f"**è¯„ä¼°åˆ†æ•°**: {paper['assessment_score']}/10\n\n")
                    if 'assessment_reasoning' in paper:
                        f.write(f"**æ¨èç†ç”±**: {paper['assessment_reasoning']}\n\n")

                    f.write("---\n\n")

            print(Fore.GREEN + f"\nğŸ’¾ å‚è€ƒæ–‡çŒ®å·²ä¿å­˜è‡³: {filename}")
            print(Fore.CYAN + f"ğŸ“Š å…±æ¨è {len(ranked_papers)} ç¯‡é«˜è´¨é‡è®ºæ–‡")

        except Exception as e:
            print(Fore.RED + f"\nâŒ ä¿å­˜å¤±è´¥: {e}")

    def run(self):
        try:
            # 1. ç”Ÿæˆæçº²
            self.generate_outline()
            # 2. å¼€å§‹åä½œä¼˜åŒ–
            final_outline = self.start_collaborative_writing(rounds=1)
            # 3. ä¿å­˜æœ€ç»ˆæçº²
            self.save_final_outline(final_outline)
            # 4. ä½¿ç”¨ArXivçˆ¬è™«æŸ¥æ‰¾å¹¶è¯„ä¼°å‚è€ƒæ–‡çŒ®
            self.search_and_save_references(final_outline)

        except KeyboardInterrupt:
            print(Fore.YELLOW + "\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        except Exception as e:
            print(Fore.RED + f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")


# è¿è¡Œç³»ç»Ÿ
if __name__ == "__main__":
    system = StreamingPaperWritingSystem()
    system.run()